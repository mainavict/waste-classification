{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è Warning: C:/Users/Victor/OneDrive/Documents/hackthorn/dataset\\organic does not exist!\n",
      "‚ö†Ô∏è Warning: C:/Users/Victor/OneDrive/Documents/hackthorn/dataset\\recyclable does not exist!\n",
      "\n",
      "üéâ Model trained in batches and saved as 'svm_incremental.pkl'.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import joblib\n",
    "from skimage.io import imread\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.transform import resize\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "# Define paths\n",
    "input_path = 'C:/Users/Victor/OneDrive/Documents/hackthorn/dataset'\n",
    "categories = ['organic', 'recyclable']\n",
    "batch_size = 50\n",
    "\n",
    "# Initialize model and scaler\n",
    "base_model = SGDClassifier(loss=\"hinge\")  # Base SVM model (no probability)\n",
    "model = CalibratedClassifierCV(base_model, cv=3)  # Enables probability estimation\n",
    "scaler = MinMaxScaler()  # Normalize pixel values (better for images)\n",
    "is_first_batch = True\n",
    "\n",
    "def load_images_in_batches():\n",
    "    \"\"\"Generator to yield images in small batches.\"\"\"\n",
    "    data, labels = [], []\n",
    "    \n",
    "    for category_index, category in enumerate(categories):\n",
    "        category_path = os.path.join(input_path, category)\n",
    "        if not os.path.exists(category_path):\n",
    "            print(f\"‚ö†Ô∏è Warning: {category_path} does not exist!\")\n",
    "            continue\n",
    "\n",
    "        files = os.listdir(category_path)[:400]  # Limit per category\n",
    "        for file in files:\n",
    "            img_path = os.path.join(category_path, file)\n",
    "            try:\n",
    "                # Load and preprocess image\n",
    "                image = imread(img_path).astype(np.float32)\n",
    "                if len(image.shape) == 3:  # Convert to grayscale if RGB\n",
    "                    image = resize(image, (256, 256))\n",
    "                    image = rgb2gray(image)\n",
    "                \n",
    "                data.append(image.flatten())  # Flatten image\n",
    "                labels.append(category_index)\n",
    "\n",
    "                # Yield batch\n",
    "                if len(data) >= batch_size:\n",
    "                    X_batch, y_batch = np.array(data), np.array(labels)\n",
    "                    unique_classes = np.unique(y_batch)\n",
    "\n",
    "                    if len(unique_classes) > 1:  # Ensure batch has both classes\n",
    "                        yield X_batch, y_batch\n",
    "                    else:\n",
    "                        print(\"‚ö†Ô∏è Skipping batch with only one class.\")\n",
    "\n",
    "                    data, labels = [], []  # Reset batch\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Error processing {img_path}: {e}\")\n",
    "\n",
    "    # Yield last batch if not empty\n",
    "    if data:\n",
    "        X_batch, y_batch = np.array(data), np.array(labels)\n",
    "        if len(np.unique(y_batch)) > 1:\n",
    "            yield X_batch, y_batch\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è Skipping last batch with only one class.\")\n",
    "\n",
    "# Train model incrementally\n",
    "batch_count = 0\n",
    "for X_batch, y_batch in load_images_in_batches():\n",
    "    X_batch = scaler.fit_transform(X_batch)  # Normalize data\n",
    "\n",
    "    if is_first_batch:\n",
    "        model.fit(X_batch, y_batch)  # First batch: Train from scratch\n",
    "        is_first_batch = False\n",
    "    else:\n",
    "        model.base_estimator.partial_fit(X_batch, y_batch, classes=np.array([0, 1]))  # Incremental training\n",
    "\n",
    "    batch_count += 1\n",
    "    print(f\"‚úÖ Processed batch {batch_count}\")\n",
    "\n",
    "# Save model and scaler\n",
    "joblib.dump(model, \"svm_incremental.pkl\")\n",
    "joblib.dump(scaler, \"scaler.pkl\")\n",
    "print(\"\\nüéâ Model trained in batches and saved as 'svm_incremental.pkl'.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "storefront-ae6rsIOs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
